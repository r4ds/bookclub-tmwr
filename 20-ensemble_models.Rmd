# Ensemble models

**Learning objectives:**

- Create a data stack for the `{stacks}` package using `stacks()` and `add_candidates`.
- Fit a **meta-learning model** using `blend_predictions()`.
- Fit the **member models** using `fit_members()`.
- Test the results of an ensemble model.

## Ensembling

- Aggregating predictions of multiple models together to make one prediction.
- We've already seen some ensembling within 1 type of model:
  - Random forest
  - Bagging & boosting
  
- **Model stacking** allows for aggregating many different types of models (lm + rf + svm, ...), to assemble a new model, which generates a new prediction, informed by its *members*.

## Ensembling with `stacks`!

![](https://raw.githubusercontent.com/tidymodels/stacks/main/man/figures/logo.png){width=25%}

https://stacks.tidymodels.org/articles/basics.html

Model stacking process:

1. Define some models, using all the knowledge we have from this book. We call them *candidate models/members*.
2. Initialize the ensemble with `stacks::stacks()`, and add the members to it, using `stacks::add_members()`
3. Blend the predictions of the members, using `stacks::blend_predictions()` (linear combination of each member's predictions)
4. Now that we know how to blend members, `fit` the members one more time on the whole training set, and `predict` on testing set.

## Define some models

- Ensembles are formed from model definitions, which are `workflow`s that contain model recipe & spec (that has been tuned or fit_resample'd).
- The book recommends the racing tuning method.

![](images/20_model-definitions.PNG)

- You’ll need to save the assessment set predictions and workflow utilized in your `tune_grid()`, or `fit_resamples()` objects by setting the control arguments `save_pred = TRUE` and `save_workflow = TRUE`. 

- If a model has hyperparameters, then you'd be creating multiple candidate models.

![](images/20_model-definitions-hyperparameters.PNG)

## Initialize and add members to stack.

- Data stacks are tibbles (with some extra attributes) that contain the response value as the first column, and the assessment set predictions for each candidate ensemble member.

![](images/20_model-stack.PNG)

```{r 20-stack_setup, eval=FALSE}
tree_frogs_model_st <- # example from stacks vignette
  stacks() %>%
  add_candidates(knn_res) %>%
  add_candidates(lin_reg_res) %>%
  add_candidates(svm_res)

tree_frogs_model_st
#> # A data stack with 3 model definitions and 11 candidate members:
#> #   knn_res: 4 model configurations
#> #   lin_reg_res: 1 model configuration
#> #   svm_res: 6 model configurations
#> # Outcome: latency (numeric)

as_tibble(tree_frogs_model_st)
#> # A tibble: 429 x 12
#>    latency knn_res_1_1 knn_res_1_2 knn_res_1_3 knn_res_1_4 lin_reg_res_1_1
#>      <dbl>       <dbl>       <dbl>       <dbl>       <dbl>           <dbl>
#>  1     142      -0.496      -0.478      -0.492      -0.494           114. 
#>  2      79      -0.381      -0.446      -0.542      -0.553            78.6
#>  3      50      -0.311      -0.352      -0.431      -0.438            81.5
#>  4      68      -0.312      -0.368      -0.463      -0.473            78.6
#>  5      64      -0.496      -0.478      -0.492      -0.494            36.5
#>  6      52      -0.391      -0.412      -0.473      -0.482           124. 
#>  7      39      -0.523      -0.549      -0.581      -0.587            35.2
#>  8      46      -0.523      -0.549      -0.581      -0.587            37.1
#>  9     137      -0.287      -0.352      -0.447      -0.456            78.8
#> 10      73      -0.523      -0.549      -0.581      -0.587            38.8
#> # … with 419 more rows, and 6 more variables: svm_res_1_1 <dbl>,
#> #   svm_res_1_4 <dbl>, svm_res_1_3 <dbl>, svm_res_1_5 <dbl>, svm_res_1_2 <dbl>,
#> #   svm_res_1_6 <dbl>
```

## Blend, fit, predict

- `blend_predictions()` performs LASSO regularization to combine the outputs from the stack members to come up with one final prediction.
- Candidates with non-zero coefficients are kept.

```{r 20-stack_blend, eval=FALSE}
tree_frogs_model_st <-
  tree_frogs_data_st %>%
  blend_predictions()
```

- There's an `autoplot()` function available, to see what's going on.
- If you don't like what you're seeing, you can try `blend_predictions()` again, and setting your own penalty argument.

![](images/20_autoplot.PNG)

- Essentially, what you have, is a linear combination of each member's prediction, to create one final prediction.

![](images/20_weights.PNG)

- With this "instruction" on how to combine candidate models, we fit the whole training set

```{r 20-stack_fit_members, eval=FALSE}
tree_frogs_model_st <-
  tree_frogs_model_st %>%
  fit_members()
```

![](images/20_blend_predictions.PNG)

- And predict on testing set

```{r 20-stack_predict, eval=FALSE}
tree_frogs_test <- 
  tree_frogs_test %>%
  bind_cols(predict(tree_frogs_model_st, .))
```


## Meeting Videos

### Cohort 1

`r knitr::include_url("https://www.youtube.com/embed/J8rZ1u4PhM8")`

`r knitr::include_url("https://www.youtube.com/embed/Pdm9G8nfR1g")`

<details>
  <summary> Meeting chat log </summary>
  
```
# 2021-05-25 Preview with Asmae Toumi
00:07:45	tan-iphone:	timed with an audience
00:08:00	tan-iphone:	did you get the cursive IDE set up?
00:11:00	Tony ElHabr:	yup! victor mono is the secret
00:18:44	tan-iphone:	foreach
00:18:47	tan-iphone:	or future or something
00:18:53	Marschall Furman (he/him):	parallel package
00:19:55	Jim Gruman:	all_cores <- parallelly::availableCores(omit = 1)
future::plan("multisession", workers = all_cores) # on Windows
00:47:55	tan-iphone:	"you'll learn when you grow up"

# 2021-06-01 Preview with Tony ElHabr
00:08:56	Jon Harmon:	Like tensorflow but very few insane installation issues: https://github.com/mlverse/torch
00:23:46	Daryn Ramsden:	Is it multinom_reg because there’s a logistic regression under the hood?
00:25:18	Jon Harmon:	I think so, as far as google is telling me.
00:27:19	Asmae Toumi:	Max’s quote: “One other note that is in the upcoming ensemble chapter about racing and stacking... the stack can only use the candidates that had the complete set of resamples done. With racing, it works fast by avoiding using all of the resamples for candidates that show poor performance. If the racing method quickly gets down to one tuning parameter set, that is the only candidate that can be added to the data stack (since it has the whole set of resamples.”
00:27:26	Pavitra:	Why is there a rank jump from 2  to 12?
00:27:51	Jon Harmon:	By model. It's showing the top 2 of each.
00:28:00	Daryn Ramsden:	ohhhh
00:28:35	Jon Harmon:	Er not by model per se but by... some combo....
00:28:41	Daryn Ramsden:	So models ranked 3-11 are also rf?
00:31:58	Asmae Toumi:	i’d be curious to see the stacks results without tune race anova
00:33:16	Jon Harmon:	beepr always reminds me of this silliness that I had running a year and a half ago or so when Max had mentioned {tune} somewhere but the repo was still private... and it exactly solved something I was working on so I wanted to know as soon as it was public:
tune_check <- httr::GET(
  url = "https://github.com/tidymodels/tune"
)
while (httr::status_code(tune_check) == 404) {
  Sys.sleep(15*60)
  tune_check <- httr::GET(
    url = "https://github.com/tidymodels/tune"
  )
}
beepr::beep(8)
00:58:21	Asmae Toumi:	Tony hive forever
00:58:48	Asmae Toumi:	Can you send the code and data? I want to understand it better too
01:00:11	Pavitra:	Ledell
01:00:13	Asmae Toumi:	Erin LeDell is a legend
01:00:22	Asmae Toumi:	It was so funny
01:01:53	Pavitra:	Thank you Tony!! This was awesome
01:01:54	Jim Gruman:	thank you!!
01:02:00	Andrew G. Farina:	Thank you Tony!

```
</details>

